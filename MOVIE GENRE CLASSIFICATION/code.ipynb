{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training and test data\n",
    "train_data=pd.read_csv('Genre Classification Dataset/train_data.txt',sep=\":::\",names=[\"Movie_name\",\"Genere\",\"Description\"],engine=\"python\")\n",
    "test_data = pd.read_csv('Genre Classification Dataset/test_data.txt',sep=\":::\",names=[\"Movie_name\",\"Description\"],engine=\"python\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Genere</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oscar et la dame rose (2009)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cupid (1997)</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Young, Wild and Wonderful (1980)</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Secret Sin (1915)</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Unrecovered (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>The film's title refers not only to the un-re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Movie_name      Genere  \\\n",
       "1       Oscar et la dame rose (2009)       drama    \n",
       "2                       Cupid (1997)    thriller    \n",
       "3   Young, Wild and Wonderful (1980)       adult    \n",
       "4              The Secret Sin (1915)       drama    \n",
       "5             The Unrecovered (2007)       drama    \n",
       "\n",
       "                                         Description  \n",
       "1   Listening in to a conversation between his do...  \n",
       "2   A brother and sister with a past incestuous r...  \n",
       "3   As the bus empties the students for their fie...  \n",
       "4   To help their unemployed father make ends mee...  \n",
       "5   The film's title refers not only to the un-re...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edgar's Lunch (1998)</td>\n",
       "      <td>L.R. Brane loves his life - his car, his apar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La guerra de papá (1977)</td>\n",
       "      <td>Spain, March 1964: Quico is a very naughty ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Off the Beaten Track (2010)</td>\n",
       "      <td>One year in the life of Albin and his family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meu Amigo Hindu (2015)</td>\n",
       "      <td>His father has died, he hasn't spoken with hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Er nu zhai (1955)</td>\n",
       "      <td>Before he was known internationally as a mart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Movie_name  \\\n",
       "1          Edgar's Lunch (1998)    \n",
       "2      La guerra de papá (1977)    \n",
       "3   Off the Beaten Track (2010)    \n",
       "4        Meu Amigo Hindu (2015)    \n",
       "5             Er nu zhai (1955)    \n",
       "\n",
       "                                         Description  \n",
       "1   L.R. Brane loves his life - his car, his apar...  \n",
       "2   Spain, March 1964: Quico is a very naughty ch...  \n",
       "3   One year in the life of Albin and his family ...  \n",
       "4   His father has died, he hasn't spoken with hi...  \n",
       "5   Before he was known internationally as a mart...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie_name     0\n",
      "Genere         0\n",
      "Description    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop_words= stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    words = word_tokenize(text)  # Tokenize text\n",
    "    words = [word for word in words if word not in stop_words and len(word) > 2 and word not in string.punctuation]  # Remove stop words, short words, and punctuation\n",
    "    text = \" \".join(words)  # Join words back into a single string\n",
    "    return text\n",
    "\n",
    "train_data['Description'] = train_data['Description'].apply(clean_text)\n",
    "test_data['Description'] = test_data['Description'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature Extraction (Text- Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()  \n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = vectorizer.fit_transform(train_data['Description'])\n",
    "y_train = label_encoder.fit_transform(train_data['Genere'])\n",
    "\n",
    "# Transform the test data\n",
    "X_test = vectorizer.transform(test_data['Description'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes model trained.\n",
      "Logistic Regression model trained.\n",
      "SVC model trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "k=10000\n",
    "\n",
    "# Naive Bayes (no scaling needed)\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "print(\"Naive Bayes model trained.\")\n",
    "\n",
    "# Logistic Regression with Standard Scaling and SelectKBest\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('select_k_best', SelectKBest(chi2, k=k)),\n",
    "    ('logistic_regression', LogisticRegression(max_iter=10000))  # Increased max_iter\n",
    "])\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "print(\"Logistic Regression model trained.\")\n",
    "\n",
    "# SVM with Standard Scaling and SelectKBest\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('select_k_best', SelectKBest(chi2, k=k)),\n",
    "    ('svm', SVC(kernel='linear', max_iter=10000))  # Increased max_iter\n",
    "])\n",
    "\n",
    "# Train SVM model\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "print(\"SVC model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.4446494464944649\n",
      "Logistic Regression Accuracy: 0.26629151291512915\n",
      "SVM Accuracy: 0.1114760147601476\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1314\n",
      "           1       0.00      0.00      0.00       590\n",
      "           2       0.00      0.00      0.00       775\n",
      "           3       0.00      0.00      0.00       498\n",
      "           4       0.00      0.00      0.00       264\n",
      "           5       0.71      0.04      0.08      7446\n",
      "           6       0.00      0.00      0.00       505\n",
      "           7       0.53      0.90      0.67     13096\n",
      "           8       0.38      0.88      0.53     13612\n",
      "           9       0.00      0.00      0.00       783\n",
      "          10       0.00      0.00      0.00       322\n",
      "          11       0.00      0.00      0.00       193\n",
      "          12       0.00      0.00      0.00       243\n",
      "          13       0.00      0.00      0.00      2204\n",
      "          14       0.00      0.00      0.00       731\n",
      "          15       0.00      0.00      0.00       276\n",
      "          16       0.00      0.00      0.00       318\n",
      "          17       0.00      0.00      0.00       181\n",
      "          18       0.00      0.00      0.00       883\n",
      "          19       0.00      0.00      0.00       672\n",
      "          20       0.00      0.00      0.00       646\n",
      "          21       1.00      0.01      0.01      5072\n",
      "          22       0.00      0.00      0.00       431\n",
      "          23       0.00      0.00      0.00       391\n",
      "          24       0.00      0.00      0.00      1590\n",
      "          25       0.00      0.00      0.00       132\n",
      "          26       1.00      0.00      0.00      1032\n",
      "\n",
      "    accuracy                           0.44     54200\n",
      "   macro avg       0.13      0.07      0.05     54200\n",
      "weighted avg       0.43      0.44      0.31     54200\n",
      "\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.00      0.00      1314\n",
      "           1       0.45      0.11      0.18       590\n",
      "           2       0.50      0.10      0.17       775\n",
      "           3       1.00      0.01      0.03       498\n",
      "           4       0.17      0.00      0.01       264\n",
      "           5       0.18      0.00      0.01      7446\n",
      "           6       0.00      0.00      0.00       505\n",
      "           7       0.30      0.01      0.03     13096\n",
      "           8       0.26      0.98      0.41     13612\n",
      "           9       0.00      0.00      0.00       783\n",
      "          10       0.50      0.01      0.01       322\n",
      "          11       0.56      0.41      0.47       193\n",
      "          12       0.05      0.02      0.03       243\n",
      "          13       0.14      0.00      0.00      2204\n",
      "          14       0.00      0.00      0.00       731\n",
      "          15       0.12      0.00      0.01       276\n",
      "          16       0.14      0.00      0.01       318\n",
      "          17       0.10      0.03      0.04       181\n",
      "          18       0.18      0.02      0.03       883\n",
      "          19       0.00      0.00      0.00       672\n",
      "          20       0.00      0.00      0.00       646\n",
      "          21       0.15      0.00      0.00      5072\n",
      "          22       0.46      0.14      0.21       431\n",
      "          23       0.00      0.00      0.00       391\n",
      "          24       0.00      0.00      0.00      1590\n",
      "          25       0.02      0.01      0.01       132\n",
      "          26       0.71      0.52      0.60      1032\n",
      "\n",
      "    accuracy                           0.27     54200\n",
      "   macro avg       0.24      0.09      0.08     54200\n",
      "weighted avg       0.24      0.27      0.13     54200\n",
      "\n",
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.00      0.00      1314\n",
      "           1       0.48      0.13      0.20       590\n",
      "           2       0.57      0.12      0.19       775\n",
      "           3       1.00      0.01      0.03       498\n",
      "           4       0.00      0.00      0.00       264\n",
      "           5       0.07      0.00      0.00      7446\n",
      "           6       0.00      0.00      0.00       505\n",
      "           7       0.23      0.00      0.00     13096\n",
      "           8       0.19      0.00      0.01     13612\n",
      "           9       0.00      0.00      0.00       783\n",
      "          10       0.67      0.01      0.01       322\n",
      "          11       0.79      0.16      0.26       193\n",
      "          12       0.07      0.02      0.03       243\n",
      "          13       0.11      0.00      0.00      2204\n",
      "          14       0.00      0.00      0.00       731\n",
      "          15       0.00      0.00      0.00       276\n",
      "          16       0.17      0.00      0.01       318\n",
      "          17       0.14      0.03      0.05       181\n",
      "          18       0.20      0.04      0.07       883\n",
      "          19       0.00      0.00      0.00       672\n",
      "          20       0.00      0.00      0.00       646\n",
      "          21       0.10      0.99      0.18      5072\n",
      "          22       0.35      0.22      0.27       431\n",
      "          23       0.00      0.00      0.00       391\n",
      "          24       0.00      0.00      0.00      1590\n",
      "          25       0.05      0.01      0.01       132\n",
      "          26       0.63      0.61      0.62      1032\n",
      "\n",
      "    accuracy                           0.11     54200\n",
      "   macro avg       0.22      0.09      0.07     54200\n",
      "weighted avg       0.18      0.11      0.04     54200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_data_solution = pd.read_csv('Genre Classification Dataset/test_data_solution.txt', sep=\":::\", names=[\"Movie_name\", \"Genere\", \"Description\"], engine=\"python\")\n",
    "\n",
    "# Encode test labels\n",
    "y_test = label_encoder.transform(test_data_solution['Genere'])\n",
    "\n",
    "# Predictions\n",
    "nb_pred = nb_model.predict(X_test)\n",
    "lr_pred = lr_pipeline.predict(X_test)\n",
    "svm_pred = svm_pipeline.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "\n",
    "# Classification reports with zero_division handling\n",
    "nb_report = classification_report(y_test, nb_pred, zero_division=0)\n",
    "lr_report = classification_report(y_test, lr_pred, zero_division=0)\n",
    "svm_report = classification_report(y_test, svm_pred, zero_division=0)\n",
    "\n",
    "print(f\"Naive Bayes Accuracy: {nb_accuracy}\")\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy}\")\n",
    "print(f\"SVM Accuracy: {svm_accuracy}\")\n",
    "\n",
    "print(\"\\nNaive Bayes Classification Report:\\n\", nb_report)\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", lr_report)\n",
    "print(\"\\nSVM Classification Report:\\n\", svm_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
